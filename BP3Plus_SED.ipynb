{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad2a07de-4adc-4247-8caf-424abcf2755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>RelativeFrequency</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.178561</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.251899</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.236906</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.167104</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.094295</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.044341</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.017872</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>SED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Value  RelativeFrequency Name\n",
       "0      1           0.178561  SED\n",
       "1      2           0.251899  SED\n",
       "2      3           0.236906  SED\n",
       "3      4           0.167104  SED\n",
       "4      5           0.094295  SED\n",
       "5      6           0.044341  SED\n",
       "6      7           0.017872  SED\n",
       "7      8           0.006303  SED"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Written by GC -- 03/24\n",
    "\n",
    "#This notebook contains code to generate SEDs dists for each NTS sheet. The basic idea here is to 1) determine the number of days where the FWI exceeds some threshold \n",
    "#(see https://doi.org/10.1016/j.scitotenv.2023.161831), 2) calculate the average fire duration per NTS sheet and then multiply these values to get the avg SEDs per NTS sheet. \n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import contextily as cx\n",
    "import libpysal\n",
    "import rioxarray as rxr\n",
    "from ztp_funcs import ztp_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c765d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\1119054872.py:11: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ecozones=pd.concat([df_ecozones,df_bsw,df_bse],ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#Calc number of days above some FWI value using the ecozone FWI cutoffs found in https://doi.org/10.1016/j.scitotenv.2023.161831\n",
    "\n",
    "#Read in NTS sheet shapefiles\n",
    "df_nts=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\nts_snrc\\\\nts_snrc_250k.shp\")\n",
    "\n",
    "#Read in Ecozne shapefiles. The boreal shield ecozone conatins an EW split unique to this paper, hence the\n",
    "#extra shape files\n",
    "df_ecozones=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\ecozone_shp\\\\Ecozones\\\\ecozones.shp\")\n",
    "df_bsw=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Documents\\\\BSW.shp\")\n",
    "df_bse=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Documents\\\\BSE.shp\")\n",
    "df_ecozones=pd.concat([df_ecozones,df_bsw,df_bse],ignore_index=True)\n",
    "df_ecozones=df_ecozones.drop([15])\n",
    "df_ecozones.reset_index(inplace=True)\n",
    "\n",
    "#Reproject to equal-area EASE grid\n",
    "df_nts=df_nts.to_crs(epsg=6931)\n",
    "df_ecozones=df_ecozones.to_crs(epsg=6931)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b2105fb-8b60-4738-98c8-f754cbcdd211",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add FWI cutoff values to ecozone dataframe. Where https://doi.org/10.1016/j.scitotenv.2023.161831 \n",
    "#does not provide an FWI value I just assume 19\n",
    "tdf=df_ecozones.copy()\n",
    "FWI_50=[19,19,19,19,19,19,10.5,17.7,19.6,16.7,20.8,19,11.5,11.5,9.5,11.5,23.2,30,11.5,19,20.8,19,19,19,15.8,12]\n",
    "tdf['FWI_50']=FWI_50\n",
    "FWI50_dict=pd.Series(tdf['FWI_50'].values,index=tdf['ZONE_NAME']).to_dict()\n",
    "#print(FWI50_dict)\n",
    "\n",
    "#Checks NTS sheets to see if they stradle ecozone boundaries and takes weighted average for more accurate \n",
    "#FWI cutoff values if needed\n",
    "nts_list,FWI_cf_list=[],[]\n",
    "for index, row in df_nts.iterrows():\n",
    "    int_poly=df_ecozones.intersection(row.geometry).area\n",
    "    ar=int_poly/np.sum(int_poly)\n",
    "    tdf['Area_ratio']=ar\n",
    "    ar_dict=tdf.groupby('ZONE_NAME')['Area_ratio'].sum().to_dict()\n",
    "    FWI_cf=sum(ar_dict[k]*FWI50_dict[k] for k in ar_dict)\n",
    "    FWI_cf_list.append(FWI_cf)\n",
    "    nts_list.append(row['NTS_SNRC'])\n",
    "\n",
    "#Create FWI cutoff dataframe\n",
    "tdict = {'NTS_SNRC': nts_list, 'FWI_cf': FWI_cf_list} \n",
    "df_fwi_cf=pd.DataFrame(tdict)\n",
    "df_nts_fwi_cf=df_nts.merge(df_fwi_cf, on='NTS_SNRC')\n",
    "df_nts_fwi_cf=df_nts_fwi_cf.to_crs(epsg=3857)\n",
    "df_nts_fwi_cf.to_file(r\"C:\\Users\\GiovanniCorti\\Documents\\Wildfire\\FWI_cf.shp\")\n",
    "#df_nts_fwi_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77224756-9de3-4580-a4cc-cefb45050a9d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m FWI_cf\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFWI_cf\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m dir_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mclient-data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdemo_projects\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mclimate85\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mWorking_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNARR_weather_csvs\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mNTS_SNRC_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mNTS_code\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dir_path):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#Read in fwi_era data\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     fwi_fp\u001b[38;5;241m=\u001b[39mdir_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mfwi_era_NTS_SNRC_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mNTS_code\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m     fwi_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(fwi_fp)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#Threshold FWI files and save to Y: drive\n",
    "for index, row in df_nts_fwi_cf.iterrows():\n",
    "    NTS_code=row['NTS_SNRC']\n",
    "    FWI_cf=row['FWI_cf']\n",
    "    dir_path=\"Y:\\\\client-data\\\\demo_projects\\\\climate85\\\\Working_data\\\\NARR_weather_csvs\\\\NTS_SNRC_\"+NTS_code\n",
    "    if os.path.exists(dir_path):\n",
    "        #Read in fwi_era data\n",
    "        fwi_fp=dir_path+\"\\\\fwi_era_NTS_SNRC_\"+NTS_code+\".csv\"\n",
    "        fwi_df=pd.read_csv(fwi_fp)\n",
    "        #Threshold data and save to Y: drive\n",
    "        fwi_cf_df=fwi_df[fwi_df['fwi']>FWI_cf]\n",
    "        fwi_cf_df.to_csv(dir_path+\"\\\\fwi_era_cf_NTS_SNRC_\"+NTS_code+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b788767-26e1-4222-b146-74170145e2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    NTS_SNRC            NAME_ENG             NOM_FRA  SRID  SHAPE_AREA  \\\n",
      "0       002E             BOTWOOD             BOTWOOD     6         2.0   \n",
      "1       002F         WESLEYVILLE         WESLEYVILLE     6         2.0   \n",
      "2       001K           TREPASSEY           TREPASSEY     6         2.0   \n",
      "3       001L        ST. LAWRENCE        ST. LAWRENCE     6         2.0   \n",
      "4       001M           BELLEORAM           BELLEORAM     6         2.0   \n",
      "..       ...                 ...                 ...   ...         ...   \n",
      "621     117B  DAVIDSON MOUNTAINS  DAVIDSON MOUNTAINS     6         2.0   \n",
      "622     117D     HERSCHEL ISLAND     HERSCHEL ISLAND     6         4.0   \n",
      "623     096A    JOHNNY HOE RIVER    JOHNNY HOE RIVER     6         2.0   \n",
      "624     096E        NORMAN WELLS        NORMAN WELLS     6         2.0   \n",
      "625     096F         MAHONY LAKE         MAHONY LAKE     6         2.0   \n",
      "\n",
      "     SHAPE_LEN   ign_num                                           geometry  \\\n",
      "0          6.0  1.033763  POLYGON ((-6232035.649 6274863.105, -6233890.9...   \n",
      "1          6.0  0.488773  POLYGON ((-6009396.587 6274863.105, -6011251.9...   \n",
      "2          6.0  2.168252  POLYGON ((-6009396.588 5780350.756, -6011251.9...   \n",
      "3          6.0  0.616688  POLYGON ((-6232035.647 5780350.756, -6233890.9...   \n",
      "4          6.0  1.872848  POLYGON ((-6232035.648 5942075.665, -6233890.9...   \n",
      "..         ...       ...                                                ...   \n",
      "621        6.0  0.328107  POLYGON ((-15805515.631 10446998.119, -1580737...   \n",
      "622       10.0  0.038129  POLYGON ((-15582876.782 10750787.472, -1558473...   \n",
      "623        6.0  1.921239  POLYGON ((-13579125.022 9349765.746, -13580980...   \n",
      "624        6.0  2.208884  POLYGON ((-14247042.199 9608372.886, -14248897...   \n",
      "625        6.0  2.027500  POLYGON ((-14024403.175 9608372.972, -14026258...   \n",
      "\n",
      "     FWI_cf  node_days  \n",
      "0       0.0         45  \n",
      "1       0.0         45  \n",
      "2       0.0         45  \n",
      "3       0.0         45  \n",
      "4       0.0         45  \n",
      "..      ...        ...  \n",
      "621     0.0         45  \n",
      "622     0.0         85  \n",
      "623     0.0         45  \n",
      "624     0.0         45  \n",
      "625     0.0         45  \n",
      "\n",
      "[626 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#Read in number of node-days (ERA5 nodes per NTS sheet). Used to calc percentage of ERA5 days above some FWI cutoff\n",
    "nd_df=pd.read_csv(r\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\node_days.csv\")\n",
    "df_nts_fwi_cf=df_nts_fwi_cf.merge(nd_df, on='NTS_SNRC')\n",
    "#214 is number of days between 1 April and 1 Nov, an interval that contains >99% of the fires in the NFDB\n",
    "df_nts_fwi_cf['met_samples']=df_nts_fwi_cf['node_days']*214*11\n",
    "#df_nts_fwi_cf['met_samples']=df_nts_fwi_cf['node_days']*df_nts_fwi_cf['FS_length']*11\n",
    "\n",
    "#Include only NTS sheets where an ign is defined\n",
    "df_igns=gpd.read_file(r\"C:\\Users\\GiovanniCorti\\Documents\\Wildfire\\ign_v2.shp\")\n",
    "df_nts=df_igns[df_igns['ign_num']>0]\n",
    "\n",
    "#For each NTS sheet, read ERA5 weather CSVs and calc percentage above FWI cutoff\n",
    "nts_list,per_list=[],[]\n",
    "for index, row in df_nts_fwi_cf.iterrows():\n",
    "    nts_code=row['NTS_SNRC']\n",
    "    nts_list.append(nts_code)\n",
    "    FWI_df=pd.read_csv(\"Y:\\\\client-data\\\\demo_projects\\\\climate85\\\\Working_data\\\\NARR_weather_csvs\\\\NTS_SNRC_\"+nts_code+\"\\\\fwi_era_NTS_SNRC_\"+nts_code+\".csv\")\n",
    "    per_list.append(len(FWI_df[FWI_df['fwi']>row['FWI_cf']])/row['met_samples'])\n",
    "\n",
    "#Create geodataframe w/ percentage FWI above\n",
    "tdict = {'NTS_SNRC': nts_list, 'fwi_per': per_list} \n",
    "tdf=pd.DataFrame(tdict)\n",
    "FWI_above_df=df_nts.merge(tdf, on='NTS_SNRC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f86f1562-0823-4024-9872-8435e5126e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have percenatge of FWI above cutoff we need average fire duration. This is done on an ecozone basis using fire progression data\n",
    "\n",
    "nfdb_df=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Documents\\\\Wildfire\\\\AreaBurned2010-2020\\\\NBAC_2010_2020.shp\")\n",
    "nfdb_df['EDATE']=pd.to_datetime(nfdb_df['EDATE'],exact=False)\n",
    "nfdb_df['SDATE']=pd.to_datetime(nfdb_df['SDATE'],exact=False)\n",
    "\n",
    "nfdb_df['Duration']=nfdb_df['EDATE']-nfdb_df['SDATE']\n",
    "\n",
    "#Replace 0 day duration with 1 day duration\n",
    "nfdb_df['Duration']=nfdb_df['Duration'].where(nfdb_df['Duration']!=np.timedelta64(0, 'D'),np.timedelta64(1, 'D'))\n",
    "#Assume smalls fires (less than 10 ha) with no duration have 1 day duration\n",
    "nfdb_df.loc[(nfdb_df['POLY_HA'] <10) & (np.isnat(nfdb_df['Duration'])),'Duration']=np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdbfacd-9c1d-4879-8804-4dc3b3f8260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GiovanniCorti\\Documents\\Python Scripts\\.venv\\Lib\\site-packages\\geopandas\\geodataframe.py:1528: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "#Read in ecozone shapefile and reproject to matching CRS. These are the standard ecozones instead \n",
    "#of the split boreal-sheild version used above\n",
    "ecozone_df=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\ecozone_shp\\\\Ecozones\\\\ecozones.shp\")\n",
    "ecozone_df=ecozone_df.to_crs(nfdb_df.crs)\n",
    "\n",
    "#Determine which ecozone each fire is in\n",
    "#Size cutoff here is that same as used in the ign dist calculation and is \n",
    "#inteded, in part, to implicitly account for fire supression \n",
    "nfdb_lg_df=nfdb_df[nfdb_df['POLY_HA']>1]\n",
    "for index, row in nfdb_lg_df.iterrows():\n",
    "    a=ecozone_df.intersection(row['geometry'].centroid)\n",
    "    ez_num=ecozone_df.iloc[a[~a.is_empty].index[0]]['ECOZONE']\n",
    "    nfdb_lg_df.loc[index,'ECOZONE']=ez_num\n",
    "\n",
    "#Groupby ecozone and calc average duration\n",
    "#Round long fires down to 30 days\n",
    "nfdb_lg_df.loc[nfdb_lg_df['Duration'] > np.timedelta64(30, 'D') ,'Duration']=np.timedelta64(30, 'D')\n",
    "dur_df=nfdb_lg_df.groupby('ECOZONE')['Duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84b06ac4-3307-49ee-aebb-b26204aa7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_nts=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\nts_snrc\\\\nts_snrc_250k.shp\")\n",
    "#ecozone_df=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\ecozone_shp\\\\Ecozones\\\\ecozones.shp\")\n",
    "\n",
    "#Reproj to equal-area CRS before we do calculation for sheets that straddle ecozone boundaries\n",
    "df_nts=df_nts.to_crs(epsg=6931)\n",
    "ecozone_df=ecozone_df.to_crs(epsg=6931)\n",
    "\n",
    "#Merge duration dataframe with ecozone dataframe\n",
    "tdf=ecozone_df.copy()\n",
    "tdf=tdf.merge(dur_df, on='ECOZONE')\n",
    "\n",
    "#Setup dict w/ avg duration for ecozone\n",
    "dur_dict=pd.Series(tdf['Duration'].values,index=tdf['ZONE_NAME']).to_dict()\n",
    "\n",
    "#Calc fire duration for each NTS sheet in a way that accounts for NTS sheets that straddle \n",
    "#ecozone boundaries\n",
    "nts_list,fd_list=[],[]\n",
    "for index, row in df_nts.iterrows():\n",
    "    int_poly=ecozone_df.intersection(row.geometry).area\n",
    "    ar=int_poly/np.sum(int_poly)\n",
    "    tdf['Area_ratio']=ar\n",
    "    ar_dict=tdf.groupby('ZONE_NAME')['Area_ratio'].sum().to_dict()\n",
    "    fd=sum(ar_dict[k]*(dur_dict[k]/np.timedelta64(1, 'D')) for k in ar_dict)\n",
    "    fd_list.append(fd)\n",
    "    nts_list.append(row['NTS_SNRC'])\n",
    "\n",
    "#Use ign dataframe here so we can skip NTS sheets w/ no fires.\n",
    "df_igns=gpd.read_file(r\"C:\\Users\\GiovanniCorti\\Documents\\Wildfire\\ign_v2.shp\")\n",
    "df_nts=df_igns[df_igns['ign_num']>0]\n",
    "tdict = {'NTS_SNRC': nts_list, 'avg_fd': fd_list} \n",
    "df_fd=pd.DataFrame(tdict)\n",
    "df_fd=df_nts.merge(df_fd, on='NTS_SNRC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e8bc04d-5e7c-45bf-91e4-9dba72bffe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Round min fire duration to 1 and calc avg SEDs\n",
    "df_fd.loc[df_fd['avg_fd'].between(0.01,1),'avg_fd']=1\n",
    "df_SED=df_fd[['NTS_SNRC','avg_fd']].merge(FWI_above_df, on='NTS_SNRC')\n",
    "\n",
    "#-1 here is used as I calc SEDs in excess of 1 and then add the inital SED back in. \n",
    "#This generally ensures a min of at least 1 SED.\n",
    "df_SED['SED']=(df_SED['fwi_per']*(df_SED['avg_fd']-1))+1\n",
    "\n",
    "#Spatial smoothing using nearest 8 NTS sheets\n",
    "W = libpysal.weights.KNN.from_dataframe(df_SED, k=8)\n",
    "# row-normalise weights\n",
    "W.transform = \"r\"\n",
    "df_SED[\"SED_sm\"] = libpysal.weights.lag_spatial(W, df_SED[\"SED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f43f618-e297-4707-9512-454c49ea7ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SED = gpd.GeoDataFrame(df_SED, crs=\"EPSG:6931\", geometry='geometry')\n",
    "df_SED.loc[df_SED['SED_sm'].le(1),'SED_sm']=1\n",
    "#df_SED.to_file(\"C:/Users/GiovanniCorti/Documents/Wildfire/SED_var_FSL.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccd989ec-5081-4edf-892f-abba7ddfa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SED dist .csvs for each NTS sheet. These csvs are not possion distributed and only feature 2 possible SED values.\n",
    "for index, row in df_SED.iterrows():\n",
    "    num=np.round(row['SED_sm'],2)\n",
    "    vals=np.round(np.modf(num),2)\n",
    "    SED_num_ls=[]\n",
    "    per_ls=[]\n",
    "    \n",
    "    if num==0:\n",
    "        #r1=[0,1.0]\n",
    "        SED_num_ls.append(0)\n",
    "        per_ls.append(100)\n",
    "    elif np.isnan(num):\n",
    "        pass\n",
    "    else:\n",
    "        SED_num_ls.extend((int(vals[1]),int(vals[1]+1)))\n",
    "        per_ls.extend((100*np.round(1-vals[0],2),100*np.round(vals[0],2)))\n",
    "    tdict = {'sp_ev_days': SED_num_ls, 'pct': per_ls} \n",
    "    dt=pd.DataFrame(tdict)\n",
    "    #Write .csvs to Y drive\n",
    "    dt.to_csv(\"Y:client-data\\\\demo_projects\\\\climate85\\\\Working_data\\\\SED_dist_v2\\\\sed_dist_\"+row['NTS_SNRC']+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f98bd97-fb3f-4e3b-b3aa-1a6352ac660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\2321008537.py:23: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_ecozones=pd.concat([df_ecozones,df_bsw,df_bse],ignore_index=True)\n",
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\2321008537.py:49: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_SEDv3['SED'][df_SEDv3['SED']<1]=1\n",
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\2321008537.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_SEDv3['SED'][df_SEDv3['SED']<1]=1\n"
     ]
    }
   ],
   "source": [
    "SED_v2=gpd.read_file(\"C:/Users/GiovanniCorti/Documents/Wildfire/SED_v2.shp\")\n",
    "\n",
    "#tuned_SED_dict={'Northern Arctic': None, 'Arctic Cordillera': None, 'Southern Arctic': None, 'Taiga Cordillera': 5.1148, 'Taiga Plain': 2.0798, \n",
    "#'Taiga Shield': 5.8558, 'Boreal Cordillera': 3.8857, 'Boreal PLain': 2.2377, 'Pacific Maritime': 4.7376, 'Hudson Plain': 2.52615, \n",
    "#'Montane Cordillera': 3.3510, 'Prairie': None, 'Atlantic Maritime': None, 'MixedWood Plain': None, 'Boreal Shield West': 3.3460, \n",
    "#'Boreal Shield East': 2.9079}\n",
    "\n",
    "tuned_SED_dict={'Northern Arctic': 1.0, 'Arctic Cordillera': 5.8558, 'Southern Arctic': (2.0798+5.8558)/2, 'Taiga Cordillera': 5.1148, 'Taiga Plain': 2.0798, \n",
    "'Taiga Shield': 5.8558, 'Boreal Cordillera': 3.8857, 'Boreal PLain': 2.2377, 'Pacific Maritime': 4.7376, 'Hudson Plain': 2.52615, \n",
    "'Montane Cordillera': 3.3510, 'Prairie': (2.2377+3.3510)/2, 'Atlantic Maritime': 2.9079, 'MixedWood Plain': 2.9079, 'Boreal Shield West': 3.3460, \n",
    "'Boreal Shield East': 2.9079}\n",
    "\n",
    "#Calc number of days above some FWI value using the ecozone FWI cutoffs found in https://doi.org/10.1016/j.scitotenv.2023.161831\n",
    "\n",
    "#Read in NTS sheet shapefiles\n",
    "df_nts=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\nts_snrc\\\\nts_snrc_250k.shp\")\n",
    "\n",
    "#Read in Ecozne shapefiles. The boreal shield ecozone conatins an EW split unique to this paper, hence the\n",
    "#extra shape files\n",
    "df_ecozones=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Downloads\\\\ecozone_shp\\\\Ecozones\\\\ecozones.shp\")\n",
    "df_bsw=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Documents\\\\BSW.shp\")\n",
    "df_bse=gpd.read_file(\"C:\\\\Users\\\\GiovanniCorti\\\\Documents\\\\BSE.shp\")\n",
    "df_ecozones=pd.concat([df_ecozones,df_bsw,df_bse],ignore_index=True)\n",
    "df_ecozones=df_ecozones.drop([15])\n",
    "df_ecozones.reset_index(inplace=True)\n",
    "\n",
    "#Reproject to equal-area EASE grid\n",
    "df_nts=df_nts.to_crs(epsg=6931)\n",
    "df_ecozones=df_ecozones.to_crs(epsg=6931)\n",
    "\n",
    "SED_v2=df_nts.merge(SED_v2[[\"NTS_SNRC\",\"SED_sm\"]],on=\"NTS_SNRC\")\n",
    "\n",
    "ez_ls,nts_ls,SED_ls=[],[],[]\n",
    "for index, row in SED_v2.iterrows():\n",
    "    int_poly=df_ecozones.intersection(row.geometry).area\n",
    "    ar=int_poly/np.sum(int_poly)\n",
    "    tez_ls=list(df_ecozones.iloc[ar[ar!=0.0].index]['ZONE_NAME'])    \n",
    "    tar_ls=list(ar[ar!=0.0])\n",
    "\n",
    "    ar_dict=dict(zip(tez_ls,tar_ls))\n",
    "    SED_val=sum(ar_dict[k]*tuned_SED_dict[k] for k in ar_dict)\n",
    "    SED_ls.append(SED_val)\n",
    "    nts_ls.append(row['NTS_SNRC'])\n",
    "    \n",
    "tdict = {'NTS_SNRC': nts_ls, 'SED': SED_ls} \n",
    "tdf=pd.DataFrame(tdict)\n",
    "df_SEDv3=df_nts.merge(tdf)\n",
    "\n",
    "df_SEDv3['SED'][df_SEDv3['SED']<1]=1\n",
    "#df_SEDv3.to_file(\"C:/Users/GiovanniCorti/Documents/Wildfire/SED_v3.shp\")\n",
    "df_SEDv3['SED'].min()\n",
    "df_SEDv3.to_file(\"C:/Users/GiovanniCorti/Documents/Wildfire/SED_v3.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d2414e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SED_v2=gpd.read_file(\"C:/Users/GiovanniCorti/Documents/Wildfire/SED_v2.shp\")\n",
    "#SED_v2.groupby('ECOZONE_NAME')['SED_sm'].mean()\n",
    "\n",
    "ez_ls,nts_ls=[],[]\n",
    "for index, row in df_nts.iterrows():\n",
    "    #a=row.geometry.centroid.within(df_ecozones.geometry)\n",
    "    \n",
    "    int_poly=df_ecozones.intersection(row.geometry).area\n",
    "    ar=int_poly/np.sum(int_poly)\n",
    "    \n",
    "    if pd.isnull(ar).all():\n",
    "        ez_ls.append(None)\n",
    "    elif len(ar[ar!=0.0])>0:\n",
    "        #print(ar[ar!=0.0])\n",
    "        ez_ls.append(df_ecozones.iloc[ar[ar!=0.0].idxmax()]['ZONE_NAME'])\n",
    "\n",
    "    \n",
    "    \n",
    "    #if len(a[a])==1:\n",
    "        #print(df_ecozones.iloc[a[a].index-1]['ZONE_NAME'])\n",
    "        #ez_ls.append(df_ecozones.iloc[a[a==True].index]['ZONE_NAME'].values[0])\n",
    "    else:\n",
    "        ez_ls.append(None)\n",
    "    nts_ls.append(row[\"NTS_SNRC\"])\n",
    "\n",
    "tdict = {'NTS_SNRC': nts_ls, 'ZONE_NAME': ez_ls} \n",
    "tdf=pd.DataFrame(tdict)\n",
    "SED_v2=SED_v2.merge(tdf)\n",
    "EZ_SED_mu_df=SED_v2.groupby(\"ZONE_NAME\")[\"SED_sm\"].mean()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7361da7d-a4f9-47d9-bf6b-530db9d23888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\793946050.py:15: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  SED_v4['adj_SED'][SED_v4['adj_SED']<1]=1\n",
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\793946050.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SED_v4['adj_SED'][SED_v4['adj_SED']<1]=1\n",
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\793946050.py:18: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  SED_v4['adj_SED'][SED_v4['adj_SED']>7]=7\n",
      "C:\\Users\\GiovanniCorti\\AppData\\Local\\Temp\\ipykernel_37360\\793946050.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  SED_v4['adj_SED'][SED_v4['adj_SED']>7]=7\n"
     ]
    }
   ],
   "source": [
    "sed_norm_ls,nts_ls=[],[]\n",
    "for index, row in SED_v2.iterrows():\n",
    "    if row[\"ZONE_NAME\"]!=None:\n",
    "        sed_norm_ls.append(row[\"SED_sm\"]/EZ_SED_mu_df.loc[row[\"ZONE_NAME\"]])\n",
    "        \n",
    "    else:\n",
    "        sed_norm_ls.append(None)\n",
    "    nts_ls.append(row[\"NTS_SNRC\"])\n",
    "    \n",
    "tdict = {'NTS_SNRC': nts_ls, 'SED_norm': sed_norm_ls} \n",
    "tdf=pd.DataFrame(tdict)\n",
    "SED_v4=df_SEDv3.merge(tdf)\n",
    "SED_v4[\"adj_SED\"]=SED_v4[\"SED\"]*SED_v4[\"SED_norm\"]\n",
    "#Must have at least 1 SED\n",
    "SED_v4['adj_SED'][SED_v4['adj_SED']<1]=1\n",
    "#Very large SED values can cause crashes due to memory limits. Additionally, the physics of very large fires is poorly captured by \n",
    "#models like BP3+ beacuse they are not atmospherically coupled\n",
    "SED_v4['adj_SED'][SED_v4['adj_SED']>7]=7\n",
    "SED_v4.to_file(\"C:/Users/GiovanniCorti/Documents/Wildfire/SED_fst.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2eb243d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create SED dist .csvs for each NTS sheet. These csvs are poisson distributed\n",
    "for index, row in SED_v4.iterrows():\n",
    "    ztp_df=ztp_dist('SED', row[\"adj_SED\"])\n",
    "    tdict = {'sp_ev_days': ztp_df[\"Value\"], 'pct': np.round(ztp_df[\"RelativeFrequency\"]*100,2)} \n",
    "    dt=pd.DataFrame(tdict)\n",
    "    #dt.to_csv(\"Y:client-data\\\\demo_projects\\\\climate85\\\\Working_data\\\\SED_dist_v2\\\\sed_dist_\"+row['NTS_SNRC']+'.csv',index=False)\n",
    "    dt.to_csv(\"C:\\\\Users\\\\GiovanniCorti\\\\Desktop\\\\BP3Inputs\\\\\"+row['NTS_SNRC']+\"\\\\sed_dist_\"+row['NTS_SNRC']+'.csv',index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
